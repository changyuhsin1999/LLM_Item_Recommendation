{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.1: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from func import get_user_watch_history\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "data = pd.read_csv(\"data/merged_df.csv\")\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "system_prompt = \"You are a movie recommender system that will compare user previous watch history and ratings.\"\n",
    "unique_movie_titles = set(data['title'].unique().tolist())\n",
    "\n",
    "user_id = 123\n",
    "candidate_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_df = train_data[train_data[\"userId\"] == user_id]\n",
    "test_user_df = test_data[test_data[\"userId\"] == user_id]\n",
    "\n",
    "train_title, train_rating = train_user_df[\"title\"], train_user_df[\"rating\"]\n",
    "test_title, test_rating = test_user_df[\"title\"], test_user_df[\"rating\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.2: User Filtering\n",
    "\n",
    "This principle operates on the premise that candidate movies should be appealing to users who share similarities with the target user. To accomplish this, we begin by encoding each user's watched movies into a multi-hot vector representation. Similar users are identified by comparing the target user's vector with other users' vectors using cosine similarity. We then choose the ùëö most similar users and create a candidate movie set of size ùë† by selecting the most popular movies from the films that these similar users have interacted with.\n",
    "\n",
    "We set the candidate set size as 100, since we found out that this size aligns with the GPT model's availability in processing long list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "def get_similar_users(user_id, data):\n",
    "    user_movie_matrix = data.pivot_table(index='userId', columns='title', values='rating')\n",
    "    user_movie_matrix = user_movie_matrix.fillna(0)\n",
    "    similarity_matrix = cosine_similarity(user_movie_matrix)\n",
    "    similarity_df = pd.DataFrame(similarity_matrix, index=user_movie_matrix.index, columns=user_movie_matrix.index)\n",
    "    similar_users = similarity_df[user_id].sort_values(ascending=False)\n",
    "    return similar_users\n",
    "\n",
    "similar_users = list(get_similar_users(user_id, train_data).iloc[:candidate_size].index)\n",
    "train_similar_df = train_data[train_data[\"userId\"].isin(similar_users)]\n",
    "movie_popularity = train_similar_df.groupby('title').size().sort_values(ascending=False)\n",
    "candidate1 = list(movie_popularity.head(candidate_size).head(candidate_size).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.3: Item Filtering\n",
    "\n",
    "In a manner akin to user filtering, we depict each movie using a multi-hot vector determined by the users who have engaged with it. By measuring cosine similarity between pairs of movies, we identify the 100 most closely related movies for each movie within the target user's interaction history. Subsequently, we assemble a candidate set comprising 100 items, taking into account the \"popularity\" of these akin movies relative to the ones within the target user's interaction history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movie = train_user_df[\"movieId\"]\n",
    "watched = pd.unique(train_movie).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = data.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "user_item_matrix = user_item_matrix.fillna(0)\n",
    "item_similarity = cosine_similarity(user_item_matrix.T)\n",
    "def find_similar_movies(target_item_id, data):\n",
    "    target_item_index = user_item_matrix.columns.get_loc(target_item_id)\n",
    "    similarities = item_similarity[target_item_index]\n",
    "    similar_items_df = pd.DataFrame({'movieId': user_item_matrix.columns, 'similarity_score': similarities})\n",
    "    similar_items_df = similar_items_df.sort_values(by='similarity_score', ascending=False)\n",
    "    N = candidate_size\n",
    "    top_similar_items = similar_items_df.head(N)\n",
    "    return top_similar_items\n",
    "\n",
    "similar_movies = []\n",
    "for movie in watched:\n",
    "    similar_movies.append(find_similar_movies(movie, train_data))\n",
    "similar_df = pd.concat(similar_movies)\n",
    "\n",
    "movie_popularity = similar_df.groupby('movieId').size().sort_values(ascending=False)\n",
    "candidate2 = list(movie_popularity.head(candidate_size).head(candidate_size).index)\n",
    "candidate2 = train_data.loc[train_data['movieId'].isin(candidate2), 'title'].tolist()\n",
    "candidate = list(set(candidate1) | set(candidate2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 4\n"
     ]
    }
   ],
   "source": [
    "def clean_candidate(candidate, train_title, test_title):\n",
    "    to_remove = []\n",
    "    \n",
    "    for movie in candidate:\n",
    "        if movie in train_title:\n",
    "            ro_remove.append(movie)\n",
    "            print(f\"to remove: {movie} \")\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    for movie in to_remove:\n",
    "        candidate.append(movie)\n",
    "    for movie in test_title:\n",
    "        if movie not in candidate:\n",
    "            # print(f\"not in candidate: {movie} \")\n",
    "            count1 += 1\n",
    "        else:\n",
    "            # print(movie)\n",
    "            count2 += 1\n",
    "    print(count1, count2)\n",
    "            \n",
    "    return candidate\n",
    "            \n",
    "candidate = clean_candidate(candidate, train_title, test_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the training set: 50\n",
      "The length of the testing set: 6\n",
      "The length of the candidate set: 128\n"
     ]
    }
   ],
   "source": [
    "print(f\"The length of the training set: {len(train_title)}\")\n",
    "print(f\"The length of the testing set: {len(test_title)}\")\n",
    "print(f\"The length of the candidate set: {len(candidate)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Summarize User Preferences\n",
    "\n",
    "During this step, we implemented the following enhancements:\n",
    "1. We eliminated the need for candidate sets in answer1. In fact, the inclusion of candidate sets tends to create confusion for the model due to the extended context.\n",
    "2. We incorporated movie ratings into the list of watched movies. Additionally, we positioned the ratings alongside the movie titles to facilitate easier identification and matching by the GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "movie_df = list(pd.unique(data[\"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the list of movies you've watched and their ratings, it seems like you prioritize a mix of genres, including action, thriller, science fiction, and drama. You also seem to appreciate movies with strong storytelling, character development, and plot twists. Additionally, it looks like you enjoy visually stunning and immersive films with engaging narratives. These aspects seem to be important to you when selecting movies.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "movie_rating = \"\"\n",
    "for i in range(len(train_title)):\n",
    "    movie_rating += f\"{train_title.iloc[i]}: {train_rating.iloc[i]} \\n\"\n",
    "\n",
    "if user_id in data['userId'].values:\n",
    "    titles_list, ratings_list = get_user_watch_history(user_id, data)\n",
    "    messages=[\n",
    "        # {\"role\": \"user\", \"content\": f\"Candidate Set(candidate movies): \"},\n",
    "        {\"role\": \"user\", \"content\": f\"The movies I have watched(watched movies): {movie_rating}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Step 1: What features are most important to me when selecting movies? \"},\n",
    "    ]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "answer1 = (completion.choices[0].message.content)\n",
    "answer1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: User's Favorite Movies\n",
    "\n",
    "In the second phase, this prompt encompasses the preceding prompt content, followed by the incorporation of the response from Step 1. It also introduces the directive: \"Step 2: You will select the movies ... that appeal to me the most ... presented in descending order of preference (...)\". This step aims to identify the movies previously interacted with that most accurately capture the preferences of the target user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Based on your ratings, the top 10 movies that seem to appeal to you the most are as follows:\n",
      "\n",
      "1. Star Wars: Episode IV - A New Hope (1977)\n",
      "2. The Imitation Game (2014)\n",
      "3. Nightcrawler (2014)\n",
      "4. Memento (2000)\n",
      "5. American History X (1998)\n",
      "6. Edge of Tomorrow (2014)\n",
      "7. Inglourious Basterds (2009)\n",
      "8. Fight Club (1999)\n",
      "9. Source Code (2011)\n",
      "10. Seven (a.k.a. Se7en) (1995)\n",
      "\n",
      "These films appear to align most closely with your ratings and genre preferences.\n"
     ]
    }
   ],
   "source": [
    "# movie_rating = \"\"\n",
    "# for i in range(len(train_title)):\n",
    "#     movie_rating += f\"{train_title.iloc[i]}: {train_rating.iloc[i]} \\n\"\n",
    "\n",
    "messages=[\n",
    "    {\"role\": \"user\", \"content\": f\"The movies I have watched(watched movies) and their ratings: {movie_rating}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Step 1: What features are most important to me when selecting movies? \"},\n",
    "]\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": answer1})\n",
    "                \n",
    "step2 = \"You will select the movies (at most 10 movies) that appeal to me the most from the list of movies \\\n",
    "    I have watched, based on my personal preferences. The selected movies will be presented in descending \\\n",
    "    order of preference. (Format: no. a watched movie).\"\n",
    "    \n",
    "messages.append({\"role\": \"user\", \"content\": step2})\n",
    "                \n",
    "completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "answer2 = (completion.choices[0].message.content)\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3: Recommend From Candidate\n",
    "\n",
    "Again, this prompt includes the previous text appended with the answers of Step 2. It then includes the instruction ‚ÄúStep 3: Can you recommend 10 movies from the Candidate Set similar to ...‚Äù.\n",
    "\n",
    "We enhanced this prompt in the following manner:\n",
    "1. We relocated the candidate set to be within step3. Through experimentation, we observed that when placing the candidate set at the very beginning of the conversation, the recommender often provided recommendations that fell outside the boundaries of the candidate set. To rectify this issue, we positioned these elements closer together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Based on your preferences, here are 10 recommended movies from the candidate set that you might enjoy:\n",
      "\n",
      "1. Nightcrawler (2014) : Shutter Island (2010) \n",
      "2. Memento (2000) : Inception (2010) \n",
      "3. American History X (1998) : Fight Club (1999) \n",
      "4. Edge of Tomorrow (2014) : Minority Report (2002) \n",
      "5. Inglourious Basterds (2009) : Django Unchained (2012) \n",
      "6. Seven (a.k.a. Se7en) (1995) : Zodiac (2007) \n",
      "7. Fight Club (1999) : The Matrix (1999) \n",
      "8. Source Code (2011) : Inception (2010) \n",
      "9. Lord of the Rings: The Return of the King, The (2003) : Gladiator (2000) \n",
      "10. Star Wars: Episode IV - A New Hope (1977) : Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)  \n",
      "\n",
      "These recommendations are based on the similarity to the movies you've watched and enjoyed. Enjoy your movie time!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": answer2})\n",
    "\n",
    "# messages.append({\"role\": \"user\", \"content\": f\"Candidate Set(candidate movies): {', '.join(candidate)}\"},)\n",
    "                \n",
    "step3 = \"Can you recommend 10 different movies only from the Candidate Set similar to the selected \\\n",
    "    movies I've watched (Format: [<n>. <a watched movie> : <a candidate movie>])?\" + f\"Candidate Set\\\n",
    "    (candidate movies): {', '.join(candidate)}\"\n",
    "    \n",
    "messages.append({\"role\": \"user\", \"content\": step3})\n",
    "                \n",
    "completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "answer3 = (completion.choices[0].message.content)\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Evaluation\n",
    "\n",
    "For evaluation purposes, we set aside 20% of the dataset to create a testing set. We utilize the training set for prompting and fine-tuning our Language Model (LLM). After obtaining the recommendation results, we calculate accuracy by measuring the proportion of recommended movies that match those in the testing dataset. If a recommended movie also exists in the testing set, we consider it correct, as it indicates that the user actually watched the recommended movie.\n",
    "\n",
    "Consequently, the \"3-step\" prompting model achieves an accuracy of 20%, while the \"most-popular\" model achieves an accuracy of 10%. This 20% accuracy is noteworthy, considering the large movie dataset of 10,000 items, with only approximately 10 items in the testing set.\n",
    "\n",
    "It's worth noting that the LLM model's responses may not remain consistent even when using the same prompt. To address this, we rigorously format the prompting to ensure that the GPT's responses are parseable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_answer3(answer3):\n",
    "    lines = answer3.split('\\n')\n",
    "    pattern = r': (.*?) \\((\\d+)\\)'\n",
    "    movie_pred = []\n",
    "    for line in lines:\n",
    "        match = re.search(pattern, line)\n",
    "        if match:\n",
    "            title = match.group(1)\n",
    "            year = match.group(2)\n",
    "            movie_pred.append((title, year))\n",
    "    return movie_pred\n",
    "\n",
    "def accuracy(movie_pred, test_title):\n",
    "    correct = 0\n",
    "    test_title_list = list(test_title)\n",
    "    for title, year in movie_pred:\n",
    "        if \"The\" in title:\n",
    "            title = title[4:]\n",
    "        find_candidate = 0\n",
    "        for movie in candidate:\n",
    "            if title in movie:\n",
    "                find_candidate = 1\n",
    "                break\n",
    "        if not find_candidate:\n",
    "            # print(f\"{title} not in candidate\")\n",
    "            pass\n",
    "        for movie in test_title_list:\n",
    "            if title in movie:\n",
    "                # print(f\"{title} in test\")\n",
    "                correct += 1\n",
    "                break\n",
    "    return correct / len(movie_pred)\n",
    "\n",
    "def accuracy_baseline(movie_pred, test_title):\n",
    "    correct = 0\n",
    "    test_title_list = list(test_title)\n",
    "    for movie in movie_pred:\n",
    "        if movie in test_title_list:\n",
    "            # print(f\"{movie} in test\")\n",
    "            correct += 1\n",
    "            break\n",
    "    return correct / len(movie_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "movie_pred = parse_answer3(answer3)\n",
    "print(accuracy(movie_pred, test_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "movie_popularity = train_data.groupby('title').size().sort_values(ascending=False)\n",
    "baseline_pred = []\n",
    "for movie in movie_popularity.index:\n",
    "    if movie in candidate:\n",
    "        baseline_pred.append(movie)\n",
    "    if len(baseline_pred) >= 10:\n",
    "        break\n",
    "accuracy_baseline(baseline_pred, test_title)\n",
    "print(accuracy_baseline(baseline_pred, test_title))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
