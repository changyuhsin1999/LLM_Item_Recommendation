{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.1: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from func import get_user_watch_history\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.three_step import *\n",
    "from src.baseline import *\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "user_id = 123\n",
    "candidate_size = 100\n",
    "\n",
    "data = pd.read_csv(\"data/merged_df.csv\")\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_user_df = train_data[train_data[\"userId\"] == user_id]\n",
    "train_title = train_user_df[\"title\"]\n",
    "\n",
    "test_user_df = test_data[test_data[\"userId\"] == user_id]\n",
    "test_title = test_user_df[\"title\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.0\n",
      "0.1\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.0\n",
      "0.1\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.1\n",
      "0.1\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.1\n",
      "0.1\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.0\n",
      "0.0\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.0\n",
      "0.0\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.0\n",
      "0.1\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.3\n",
      "0.1\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.2\n",
      "0.1\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.1\n",
      "0.1\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.0\n",
      "0.1\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.0\n",
      "0.0\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.0\n",
      "0.0\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.1\n",
      "0.0\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.1\n",
      "0.0\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.0\n",
      "0.0\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.1\n",
      "0.1\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.0\n",
      "0.0\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.0\n",
      "0.0\n",
      "finish step 1\n",
      "finish step 2\n",
      "finish step 3\n",
      "0.2\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "users = [30*i+7 for i in range(20)]\n",
    "\n",
    "def compare_accuracy(user_id):\n",
    "    data = pd.read_csv(\"data/merged_df.csv\")\n",
    "\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    train_user_df = train_data[train_data[\"userId\"] == user_id]\n",
    "    train_title = train_user_df[\"title\"]\n",
    "\n",
    "    test_user_df = test_data[test_data[\"userId\"] == user_id]\n",
    "    test_title = test_user_df[\"title\"]\n",
    "    \n",
    "    threeStepRecommender = ThreeStepRecommender(user_id, train_data, candidate_size)\n",
    "    movie_pred = threeStepRecommender.get_pred()\n",
    "    accuracy1 = threeStepRecommender.accuracy(movie_pred, test_title)\n",
    "    print(accuracy1)\n",
    "    \n",
    "    mostPopularRecommendor = MostPopularRecommendor(train_data)\n",
    "    baseline_pred = mostPopularRecommendor.pred()\n",
    "    accuracy2 = mostPopularRecommendor.accuracy(baseline_pred, test_title)\n",
    "    print(accuracy2)\n",
    "    \n",
    "    return accuracy1, accuracy2\n",
    "\n",
    "l1 = []\n",
    "l2 = []\n",
    "\n",
    "for user_id in users:\n",
    "    accuracy1, accuracy2 = compare_accuracy(user_id)\n",
    "    l1.append(accuracy1)\n",
    "    l2.append(accuracy2)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/yiyang/Desktop/RL Apps/LLM_Item_Recommendation/prompting_3step_simple.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yiyang/Desktop/RL%20Apps/LLM_Item_Recommendation/prompting_3step_simple.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maverage accuracy of 3-step: \u001b[39m\u001b[39m{\u001b[39;00mmean(l1)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yiyang/Desktop/RL%20Apps/LLM_Item_Recommendation/prompting_3step_simple.ipynb#Y102sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maverage accuracy of baseline: \u001b[39m\u001b[39m{\u001b[39;00mmean(l2)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"average accuracy of 3-step: {mean(l1)}\")\n",
    "print(f\"average accuracy of baseline: {mean(l2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "1. The GPT model gives results not in testing even if we specify a testing set. It only support a candidate set of around 100.\n",
    "2. The GPT gives recommendation with accuracy 0.5, while the \"most popular\" recommender only gives recommendation with accuracy 0.2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
